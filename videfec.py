import streamlit as st
import cv2
import numpy as np
from PIL import Image, ImageEnhance

def apply_glitch_effect(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image = np.array(image.convert('RGB'))
    h, w = image.shape[:2]
    glitch = image.copy()
    
    # ØªØ·Ø¨ÙŠÙ‚ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø®Ù„Ù„
    glitch[:, :w//3, 0] = np.roll(glitch[:, :w//3, 0], 10, axis=0)
    glitch[:, w//3:2*w//3, 1] = np.roll(glitch[:, w//3:2*w//3, 1], -10, axis=0)
    glitch[:, 2*w//3:, 2] = np.roll(glitch[:, 2*w//3:, 2], 15, axis=0)
    
    return Image.fromarray(glitch)

def apply_noise_effect(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image = np.array(image.convert('RGB'))
    noise = np.random.randint(0, 50, image.shape, dtype='uint8')
    noisy_image = cv2.add(image, noise)
    return Image.fromarray(noisy_image)

def apply_ghost_effect(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image = np.array(image.convert('RGB'))
    alpha = 0.5
    ghost = cv2.addWeighted(image, alpha, np.roll(image, 5, axis=1), 1 - alpha, 0)
    return Image.fromarray(ghost)

def apply_rgb_shift(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB
    pil_image = image.convert('RGB')
    image = np.array(pil_image)
    
    # ÙØµÙ„ Ø§Ù„Ù‚Ù†ÙˆØ§Øª ÙˆØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¥Ø²Ø§Ø­Ø©
    b, g, r = cv2.split(image)  # OpenCV ÙŠØ³ØªØ®Ø¯Ù… ØªØ±ØªÙŠØ¨ BGR
    r = np.roll(r, 5, axis=1)
    b = np.roll(b, -5, axis=0)
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
    shifted = cv2.merge((b, g, r))
    return Image.fromarray(shifted)

def apply_blur(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image = np.array(image.convert('RGB'))
    blurred = cv2.GaussianBlur(image, (15, 15), 0)
    return Image.fromarray(blurred)

def apply_edge_detection(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image = np.array(image.convert("L"))
    edges = cv2.Canny(image, 100, 200)
    return Image.fromarray(edges)

def apply_cartoon_effect(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB
    pil_image = image.convert('RGB')
    image = np.array(pil_image)
    
    # ØªØ­ÙˆÙŠÙ„ BGR Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    blurred = cv2.medianBlur(gray, 5)
    edges = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                  cv2.THRESH_BINARY, 9, 9)
    color = cv2.bilateralFilter(image, 9, 250, 250)
    
    # ØªØ­ÙˆÙŠÙ„ Ø­ÙˆØ§Ù Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠØ© Ø¥Ù„Ù‰ 3 Ù‚Ù†ÙˆØ§Øª Ù„Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©
    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
    cartoon = cv2.bitwise_and(color, edges_rgb)
    
    return Image.fromarray(cartoon)

def apply_negative(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB Ø«Ù… Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image = np.array(image.convert('RGB'))
    negative = cv2.bitwise_not(image)
    return Image.fromarray(negative)

def apply_sepia(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB
    pil_image = image.convert('RGB')
    image = np.array(pil_image)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­ Ø§Ù„Ø³ÙŠØ¨ÙŠØ§
    b, g, r = cv2.split(image)
    b_new = np.clip(r * 0.272 + g * 0.534 + b * 0.131, 0, 255).astype(np.uint8)
    g_new = np.clip(r * 0.349 + g * 0.686 + b * 0.168, 0, 255).astype(np.uint8)
    r_new = np.clip(r * 0.393 + g * 0.769 + b * 0.189, 0, 255).astype(np.uint8)
    
    sepia = cv2.merge([b_new, g_new, r_new])
    return Image.fromarray(sepia)

def apply_emboss(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB Ø«Ù… Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© numpy
    image = np.array(image.convert('RGB'))
    kernel = np.array([[0, -1, -1], [1, 0, -1], [1, 1, 0]])
    embossed = cv2.filter2D(image, -1, kernel)
    return Image.fromarray(embossed)

def apply_tiktok_falling_effect(image):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ RGB
    pil_image = image.convert('RGB')
    img = np.array(pil_image)
    
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø©
    h, w = img.shape[:2]
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø§Ù„Ù†ØªÙŠØ¬Ø©
    result = np.zeros_like(img)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª ÙˆØ¹Ø§Ù…Ù„ Ø§Ù„Ø­Ø±ÙƒØ©
    num_frames = 8
    max_shift = int(h * 0.15)  # Ù…Ù‚Ø¯Ø§Ø± Ø§Ù„Ø³Ù‚ÙˆØ· ÙƒÙ†Ø³Ø¨Ø© Ù…Ù† Ø§Ø±ØªÙØ§Ø¹ Ø§Ù„ØµÙˆØ±Ø©
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø³Ù‚ÙˆØ· Ù„Ù„Ø£Ù…Ø§Ù… Ø¨Ø¹Ø¯Ø© Ø·Ø¨Ù‚Ø§Øª Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
    for i in range(num_frames):
        # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø¯Ø§Ø± Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ù„Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
        shift = int((i / num_frames) * max_shift)
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙˆØ§Ù„Ù‡Ø¯Ù
        y_src_start = 0
        y_src_end = h - shift
        y_dst_start = shift
        y_dst_end = h
        
        # Ù†Ø³Ø® Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‡Ø¯Ù Ù…Ø¹ Ø¥Ø²Ø§Ø­Ø© Ù„Ù„Ø£Ø³ÙÙ„
        if y_src_end > y_src_start and y_dst_end > y_dst_start:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…ØµØ¯Ø± ÙˆØ§Ù„Ù‡Ø¯Ù
            src_region = img[y_src_start:y_src_end, :]
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø´ÙØ§ÙÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø±Ù‚Ù… Ø§Ù„Ø¥Ø·Ø§Ø± (Ø§Ù„Ø¥Ø·Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ø£ÙƒØ«Ø± Ø´ÙØ§ÙÙŠØ©)
            alpha = 1.0 - (i / num_frames) * 0.8
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø·Ø¨Ù‚Ø© Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù…Ø¹ Ø§Ù„Ø´ÙØ§ÙÙŠØ©
            if i == 0:
                # Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ØªÙƒÙˆÙ† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
                result[y_dst_start:y_dst_end, :] = src_region
            else:
                # Ø¯Ù…Ø¬ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù„Ø§Ø­Ù‚Ø© Ù…Ø¹ ØªØ£Ø«ÙŠØ± Ø§Ù„Ø´ÙØ§ÙÙŠØ©
                dst_region = result[y_dst_start:y_dst_end, :]
                result[y_dst_start:y_dst_end, :] = cv2.addWeighted(
                    dst_region, 1.0, src_region, alpha, 0
                )
    
    # Ø¥Ø¶Ø§ÙØ© ØªØ£Ø«ÙŠØ± Ø§Ù„Ø­Ø±ÙƒØ© (motion blur)
    kernel_motion_blur = np.zeros((15, 15))
    kernel_motion_blur[7, :] = np.ones(15)
    kernel_motion_blur = kernel_motion_blur / 15
    result = cv2.filter2D(result, -1, kernel_motion_blur)
    
    return Image.fromarray(result)

def main():
    st.set_page_config(page_title="Ù…Ø­Ø±Ø± ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„ØµÙˆØ±", layout="wide")
    st.title("ğŸ­ Ù…Ø­Ø±Ø± ØªØ£Ø«ÙŠØ±Ø§Øª Ø§Ù„ØµÙˆØ±")
    st.markdown("Ø¹Ø²Ø² ØµÙˆØ±Ùƒ Ø¨ØªØ£Ø«ÙŠØ±Ø§Øª Ù…Ø°Ù‡Ù„Ø©! Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£Ùˆ ØµÙˆØ±Ø© Ù…ØªØ­Ø±ÙƒØ© ÙˆØ§Ø®ØªØ± ØªØ£Ø«ÙŠØ±Ù‹Ø§ Ù„ØªØ·Ø¨ÙŠÙ‚Ù‡.")
    
    uploaded_file = st.file_uploader("Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ ØµÙˆØ±Ø© Ø£Ùˆ GIF", type=["png", "jpg", "jpeg", "gif"])
    if uploaded_file:
        image = Image.open(uploaded_file)
        effect = st.selectbox("Ø§Ø®ØªØ± ØªØ£Ø«ÙŠØ±Ù‹Ø§:", [
            "ØªØ£Ø«ÙŠØ± Ø§Ù„Ø®Ù„Ù„", "Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", "ØªØ£Ø«ÙŠØ± Ø§Ù„Ø´Ø¨Ø­", "Ø¥Ø²Ø§Ø­Ø© RGB", "ØªÙ…ÙˆÙŠÙ‡",
            "Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­ÙˆØ§Ù", "ÙƒØ±ØªÙˆÙ†", "Ù†ÙŠØ¬Ø§ØªÙŠÙ", "Ø³ÙŠØ¨ÙŠØ§", "Ø¨Ø§Ø±Ø²", "ØªØ£Ø«ÙŠØ± Ø§Ù„Ø³Ù‚ÙˆØ· Ù„Ù„Ø£Ù…Ø§Ù…"
        ])
        
        if effect == "ØªØ£Ø«ÙŠØ± Ø§Ù„Ø®Ù„Ù„":
            result = apply_glitch_effect(image)
        elif effect == "Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡":
            result = apply_noise_effect(image)
        elif effect == "ØªØ£Ø«ÙŠØ± Ø§Ù„Ø´Ø¨Ø­":
            result = apply_ghost_effect(image)
        elif effect == "Ø¥Ø²Ø§Ø­Ø© RGB":
            result = apply_rgb_shift(image)
        elif effect == "ØªÙ…ÙˆÙŠÙ‡":
            result = apply_blur(image)
        elif effect == "Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø­ÙˆØ§Ù":
            result = apply_edge_detection(image)
        elif effect == "ÙƒØ±ØªÙˆÙ†":
            result = apply_cartoon_effect(image)
        elif effect == "Ù†ÙŠØ¬Ø§ØªÙŠÙ":
            result = apply_negative(image)
        elif effect == "Ø³ÙŠØ¨ÙŠØ§":
            result = apply_sepia(image)
        elif effect == "Ø¨Ø§Ø±Ø²":
            result = apply_emboss(image)
        elif effect == "ØªØ£Ø«ÙŠØ± Ø§Ù„Ø³Ù‚ÙˆØ· Ù„Ù„Ø£Ù…Ø§Ù…":
            result = apply_tiktok_falling_effect(image)
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø«Ø©
        st.image(result, caption=f"ØªÙ… ØªØ·Ø¨ÙŠÙ‚ {effect}", use_container_width=True)

if __name__ == "__main__":
    main()